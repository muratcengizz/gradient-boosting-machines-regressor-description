{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5cd8fa-f9b1-43b9-989c-696271bb2653",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machines (GBM)\n",
    "\n",
    "\n",
    "### Gradient Boosting Machines (GBM), regresyon ve sınıflandırma problemlerinde kullanılan bir makine öğrenme algoritmasıdır. GBM, zayıf tahmincilerin (genellikle karar ağaçları) birleşimini kullanarak güçlü bir tahminci oluşturur. Her bir tahminci, önceki tahmincilerin hatalarını düzeltmek için eğitilir. Bu şekilde, GBM, hataları düzeltmek ve nihai tahmini iyileştirmek için adım adım öğrenme yeteneğine sahiptir.\n",
    "\n",
    "## GBM, aşağıdaki temel bileşenlerden oluşur:\n",
    "\n",
    "### Zayıf Tahminciler: GBM, genellikle karar ağaçları gibi zayıf tahminciler kullanır. Karar ağaçları, veri kümesindeki desenleri öğrenerek ve kararlar vererek tahmin yaparlar. GBM, genellikle birçok küçük ve basit karar ağacını birleştirir, böylece daha karmaşık ilişkileri ve etkileşimleri modelleyebilir.\n",
    "\n",
    "### Gradient Descent (Gradyan İnişi): GBM, her bir tahminciyi, önceki tahmincilerin hatalarını en aza indirecek şekilde eğitmek için gradyan iniş kullanır. Gradyan inişi, bir fonksiyonun en küçük değerine ulaşmak için adım adım kademeli bir yaklaşımı temsil eder. GBM'de, gradyan inişi kullanılarak her bir tahmincinin hataları hesaplanır ve sonraki tahmincinin bu hataları düzeltmek için eğitilir.\n",
    "\n",
    "### Öğrenme Oranı (Learning Rate): GBM'de, her bir tahmincinin sonucunu nihai tahmine katarken bir öğrenme oranı belirtilir. Öğrenme oranı, her bir tahmincinin katkısını kontrol eder. Düşük bir öğrenme oranı, modelin daha yavaş öğrenmesini sağlar, ancak daha fazla kararlılık ve genelleme yeteneği sağlar. Yüksek bir öğrenme oranı ise modelin daha hızlı öğrenmesini sağlar, ancak aşırı uyum (overfitting) riskini artırır.\n",
    "\n",
    "\n",
    "## GBM'nin bazı avantajları şunlardır:\n",
    "\n",
    "### Yüksek Tahmin Gücü: GBM, karmaşık ilişkileri ve etkileşimleri modelleyebilen güçlü tahminciler oluşturabilir. Bu nedenle, yüksek tahmin gücüne sahiptir ve genellikle makine öğrenme yarışmalarında ve gerçek dünya problemlerinde başarılı sonuçlar verir.\n",
    "\n",
    "### Esneklik: GBM, farklı kayıp fonksiyonları ve ölçütler kullanarak çeşitli problemlerde uygulanabilir. Regresyon problemlerinde kullanılan GBM'ler, sürekli bir hedef değişkenini tahminlemek için idealdir.\n",
    "\n",
    "### Ölçeklenebilirlik: GBM, büyük veri setleri üzerinde de etkili bir şekilde çalışabilir. Paralel işleme ve ölçeklenebilirliğe olanak tanıyan özellikler içerir.\n",
    "\n",
    "\n",
    "## Ancak, GBM'nin bazı dezavantajları da vardır:\n",
    "\n",
    "### Hiperparametre Ayarı: GBM'nin başarısı, birçok hiperparametrenin doğru şekilde ayarlanmasına bağlıdır. Bu, deneme yanılma yöntemiyle hiperparametre ayarının zaman alıcı olabileceği anlamına gelir.\n",
    "\n",
    "### Aşırı Uyum Riski: Yüksek öğrenme oranları veya çok fazla tahminci kullanılması durumunda GBM, eğitim verilerine aşırı uyum sağlayabilir. Bu durumda, model eğitim verilerinde iyi performans gösterirken, yeni verilerde kötü sonuç verebilir.\n",
    "\n",
    "### Hesaplama Süresi: GBM, eğitim süresi ve tahmin yapma süresi açısından zaman alıcı olabilir. Özellikle, çok sayıda tahminci kullanıldığında ve büyük veri kümeleri üzerinde çalışıldığında hesaplama süresi artabilir.\n",
    "\n",
    "\n",
    "### GBM, regresyon problemlerinde genellikle yüksek tahmin gücü ve eseneklik sağlayan etkili bir makine öğrenme algoritmasıdır. Profesyonel bir veri bilimi mühendisi, GBM'nin temel prensiplerini, hiperparametrelerini ve uygulama alanlarını anlamalıdır. Ayrıca, aşırı uyum riski ve hesaplama süresi gibi GBM'nin dezavantajlarını da dikkate almalır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1014855f-5b81-425e-a625-bed0a63b2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb69c74d-cbd6-44a5-adf1-7d7134ba1859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.9,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'squared_error',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31382cbb-1fec-4aa1-845d-eb18052e968a",
   "metadata": {},
   "source": [
    "### learning_rate: \n",
    "#### Öğrenme oranıdır. Her bir tahmincinin katkısını kontrol eder.\n",
    "#### Değer aralığı: [0, 1]\n",
    "#### Varsayılan Değer: 0.1\n",
    "\n",
    "### n_estimators:\n",
    "#### Oluşturulacak olan tahminci sayısıdır (karar ağacı sayısı).\n",
    "#### Değer aralığı: Pozitif tamsayı\n",
    "#### Varsayılan değer: 100\n",
    "\n",
    "### max_depth:\n",
    "#### Karar ağacının maksimum derinliğini sınırlar. Karar ağacının daha derin olması, modelin daha karmaşık ilişkileri öğrenmesine olanak sağlar, ancak aşırı uyum (overfitting) riskini artırır.\n",
    "#### Değer aralığı: Pozitif tamsayı veya None (sınırsız derinlik için)\n",
    "#### Varsayılan Değer: 3\n",
    "\n",
    "### min_samples_split:\n",
    "#### Bir iç düğümün bölünmesi için gereken minimum örnek sayısını belirler.\n",
    "#### Bu parametre, ağacın dallanmasının kontrol edilmesine yardımcı olur.\n",
    "#### Değer aralığı: Pozitif tamsayı veya float (örnek yüzdesi olarak ifade edilebilir).\n",
    "#### Varsayılan değer: 2\n",
    "\n",
    "\n",
    "### min_samples_leaf:\n",
    "#### Bir yaprak düğümünün minimum örnek sayısını belirler. Bu parametre, ağacın büyüklüğünü kontrol eder ve aşırı uyumu engellemeye yardımcı olur.\n",
    "#### Değer aralığı: Pozitif tamsayı veya float (örnek yüzdesi olarak ifade edilebilir).\n",
    "#### Varsayılan değer: 1\n",
    "\n",
    "\n",
    "### subsample:\n",
    "#### Her bir tahmincinin eğitim verilerinin alt kümesini kullanarak eğitilmesine olanak tanır. Daha küçük bir subsample değeri, modelin daha fazla düzensizlik ve varyansı yakalamasına yardımcı olabilir.\n",
    "#### Değer aralığı: [0, 1]\n",
    "#### Varsayılan değer: 1.0\n",
    "\n",
    "\n",
    "### loss:\n",
    "#### Kayıp fonksiyonunu belirler. Regresyon için varsayılan olarak 'ls' (Least Squares) kullanılır.\n",
    "#### Diğer seçenekler: 'lad' (Least Absolute Devation), 'huber' (Huber Loss), 'quantile' (Quantile Loss).\n",
    "#### Varsayılan değer: 'ls'\n",
    "\n",
    "\n",
    "### criterion:\n",
    "#### Karar ağacının bölünme noktalarını seçmek için kullanılan kriteri belirler.\n",
    "#### Değer aralığı: 'friedman_mse' (Friedman MSE), 'mse' (Mean Squared Error), 'mae' (Mean Absolute Error).\n",
    "#### Varsayılan değer: 'friedman_mse'\n",
    "\n",
    "\n",
    "### Bu hiperparametreler, GradientBoostingRegressor modelinin davranışını ve performansını etkiler. İyi bir model için bu parametreleri doğru şekilde ayarlamak önemlidir. Ayarlamalar, deneyler ve validasyon süreçleriyle belirlenebilir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
